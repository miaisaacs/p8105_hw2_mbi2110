Homework 2
================
Mia Isaacs
2024-09-29

# load necessary packages

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

# problem 1 - NYC transit data

Read and clean the data; retain line, station, name, station latitude /
longitude, routes served, entry, vending, entrance type, and ADA
compliance. Convert the entry variable from character (YES vs NO) to a
logical variable.

``` r
nyc_df = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) |> 
  janitor::clean_names() |> 
  select(line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) |> 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))

view(nyc_df)
```

Write a short paragraph about this dataset – explain briefly what
variables the dataset contains, describe your data cleaning steps so
far, and give the dimension (rows x columns) of the resulting dataset.
Are these data tidy?

``` r
nrow(nyc_df)
```

    ## [1] 1868

``` r
ncol(nyc_df)
```

    ## [1] 20

``` r
colnames(nyc_df)
```

    ##  [1] "line"              "station_name"      "station_latitude" 
    ##  [4] "station_longitude" "route1"            "route2"           
    ##  [7] "route3"            "route4"            "route5"           
    ## [10] "route6"            "route7"            "route8"           
    ## [13] "route9"            "route10"           "route11"          
    ## [16] "entry"             "exit_only"         "vending"          
    ## [19] "entrance_type"     "ada"

This dataset contains 19 columns and 1868 rows, consisting of the
variables line, name, latitude, longitude, routes 1-11, entrance type,
entry, vending, and ada compliance. To clean my data, I used the
clean_names step to make the variable naming convention consistent and I
selected for the variables of interest. I used a mutate step to change
the entry variable from yes/no to a logical variable and specified that
routes 8-11 should also be character. These data are not tidy because
route and route number should be variables, which means we would have to
convert them from wide to long format.

How many distinct stations are there? Note that stations are identified
both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway;
125st Lenox); the distinct function may be useful here.

``` r
nyc_df |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # ℹ 455 more rows

There are 465 distinct stations.

How many stations are ADA compliant?

``` r
nyc_df |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # ℹ 74 more rows

Only 84 stations are ADA compliant.

What proportion of station entrances / exits without vending allow
entrance?

``` r
nyc_df |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
```

    ## [1] 0.3770492

The proportion of station entrances/exits without vending allow entrance
is 0.3770492.

Reformat data so that route number and route name are distinct
variables. How many distinct stations serve the A train? Of the stations
that serve the A train, how many are ADA compliant?

``` r
nyc_df |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # ℹ 50 more rows

``` r
nyc_df |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

60 distinct stations serve the A train. Of that stations that serve the
A train, only 17 are ADA compliant.

# problem 2 - mr. trash wheel data

Read and clean the Mr. Trash Wheel sheet:specify the sheet in the Excel
file and to omit non-data entries (rows with notes / figures; columns
containing notes) using arguments in read_excel, use reasonable variable
names, omit rows that do not include dumpster-specific data, round the
number of sports balls to the nearest integer and converts the result to
an integer variable (using as.integer)

``` r
mr_trash_df =
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             na = c("NA", ".", ""),
             sheet = "Mr. Trash Wheel", range = "A2:N653") |> 
  janitor::clean_names() |> 
  rename(
    weight = weight_tons, 
    volume = volume_cubic_yards) |> 
  select(-homes_powered) |> 
  mutate(
    sports_balls = as.integer(
    round(sports_balls)),
    trash_type = "Mr. Trash Wheel",
    year = as.integer(year)
    ) 
```

Use a similar process to import, clean, and organize the data for
Professor Trash Wheel and Gwynnda, and combine this with the Mr. Trash
Wheel dataset to produce a single tidy dataset. To keep track of which
Trash Wheel is which, you may need to add an additional variable to both
datasets before combining.

``` r
prof_trash_df =
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             na = c("NA", ".", ""),
             sheet = "Professor Trash Wheel", range = "A2:M120") |> 
  janitor::clean_names() |> 
  rename(
    weight = weight_tons, 
    volume = volume_cubic_yards) |> 
  select(-homes_powered) |> 
  mutate(trash_type = "Prof. Trash Wheel",
         year = as.integer(year))
```

``` r
gwynnda_df =
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             na = c("NA", ".", ""),
             sheet = "Gwynnda Trash Wheel", range = "A2:L265") |> 
  janitor::clean_names() |> 
    rename(
    weight = weight_tons, 
    volume = volume_cubic_yards) |> 
  select(-homes_powered) |> 
  mutate(trash_type = "Gwynnda Trash Wheel",
         year = as.integer(year))
```

``` r
all_trash_df =
  bind_rows(mr_trash_df, prof_trash_df, gwynnda_df)
```

Write a paragraph about these data; you are encouraged to use inline R.
Be sure to note the number of observations in the resulting dataset, and
give examples of key variables. For available data, what was the total
weight of trash collected by Professor Trash Wheel? What was the total
number of cigarette butts collected by Gwynnda in June of 2022?

The all_trash_df consists of data from three separate Trash Wheels:
Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel. There
are 1032 total observations and the variables include dumpster, month,
year, date, weight, volume, plastic_bottles, polystyrene,
cigarette_butts, glass_bottles, plastic_bags, wrappers, sports_balls,
trash_type.

``` r
all_trash_df |> 
  filter(trash_type == "Prof. Trash Wheel") |> 
  summarise(sum(weight))
```

    ## # A tibble: 1 × 1
    ##   `sum(weight)`
    ##           <dbl>
    ## 1          247.

The total weight of trash collected by Professor Trash Wheel is 247
tons.

``` r
all_trash_df |> 
  filter(trash_type == "Gwynnda Trash Wheel", 
         month == "June",
         year == 2022) |> 
  summarise(sum(cigarette_butts))
```

    ## # A tibble: 1 × 1
    ##   `sum(cigarette_butts)`
    ##                    <dbl>
    ## 1                  18120

In June of 2022, Gwynnda collected a total of 18,120 cigarette butts.

# problem 3 - great british bake off

In the first part of this problem, your goal is to create a single,
well-organized dataset with all the information contained in these data
files. To that end: import, clean, tidy, and otherwise wrangle each of
these datasets; check for completeness and correctness across datasets
(e.g. by viewing individual datasets and using anti_join); merge to
create a single, final dataset; and organize this so that variables and
observations are in meaningful orders. Export the result as a CSV in the
directory containing the original datasets.

``` r
bakers_df =
  read_csv("data/bakers.csv") |> 
  janitor::clean_names() |> 
  separate(
    baker_name, into = c("baker", "baker_last_name"), sep = " "
  )
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_df =
  read_csv("data/bakes.csv", na = c("NA", "N/A", "UNKNOWN", "")) |> 
  janitor::clean_names() |> 
  mutate(
    baker = str_replace_all(baker, '"Jo"', "Jo")
  )
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results_df =
  read_csv("data/results.csv", skip = 2,
           na = c("NA", "N/A", "UNKNOWN", "")) |> 
  janitor::clean_names() |> 
  mutate(
    baker = str_replace_all(baker, '"Jo"', "Jo")
  )
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
anti_join(bakers_df, bakes_df, by = "baker")
```

    ## # A tibble: 22 × 6
    ##    baker  baker_last_name series baker_age baker_occupation             hometown
    ##    <chr>  <chr>            <dbl>     <dbl> <chr>                        <chr>   
    ##  1 Alice  Fevronia            10        28 Geography teacher            Essex   
    ##  2 Amelia LeBruin             10        24 Fashion designer             Halifax 
    ##  3 Antony Amourdoux            9        30 Banker                       London  
    ##  4 Briony Williams             9        33 Full-time parent             Bristol 
    ##  5 Dan    Beasley-Harling      9        36 Full-time parent             London  
    ##  6 Dan    Chambers            10        32 Support worker               Rotherh…
    ##  7 Helena Garcia              10        40 Online project manager       Leeds   
    ##  8 Henry  Bird                10        20 Student                      Durham  
    ##  9 Imelda McCarron             9        33 Countryside recreation offi… County …
    ## 10 Jamie  Finn                10        20 Part-time waiter             Surrey  
    ## # ℹ 12 more rows

``` r
anti_join(bakers_df, results_df, by = "baker")
```

    ## # A tibble: 1 × 6
    ##   baker baker_last_name series baker_age baker_occupation hometown    
    ##   <chr> <chr>            <dbl>     <dbl> <chr>            <chr>       
    ## 1 Jo    Wheatley             2        41 Housewife        Ongar, Essex

``` r
anti_join(bakes_df, results_df, by = c("series", "episode"))
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

``` r
bakeoff_df = 
  left_join(bakers_df, results_df, by = c("baker","series")) |> 
  left_join(bakes_df, by = c("baker", "series", "episode")) |> 
  relocate(series, episode, baker, result, signature_bake, show_stopper,        technical, baker_age, baker_occupation, hometown) |> 
  arrange(series, episode)
```

``` r
write_csv(bakeoff_df, "data/cleaned_bakeoff_data.csv")
```

Describe your data cleaning process, including any questions you have or
choices you made. Briefly discuss the final dataset.

To clean each of the three datasets, I used the janitor::clean_names
step to establish consistency across all variable names. There were some
missing observations in bakes_df and results_df, so I clarified what
values should be considered ‘na’. For bakers_df, I used a separate step
to separate the baker names into first and last for easier merging. The
baker Jo Wheatley’s name had been put in as “Jo”, so I used a mutate
step to change it to just Jo. Lastly, I used anti-join to see where
inconsistencies and incompleteness across the datasets was present.
There was data for 22 bakers in bakers_df that was not present in
bakes_df.

The bakeoff_df contains 1129 observations and 11 variables including
series, episode, baker, result, signature_bake, show_stopper, technical,
baker_age, baker_occupation, hometown, baker_last_name.

Create a reader-friendly table showing the star baker or winner of each
episode in Seasons 5 through 10. Comment on this table – were there any
predictable overall winners? Any surprises?

``` r
winner_df =
  results_df |> 
  filter(series >=5, series <=10) |> 
  filter(result == c("WINNER", "STAR BAKER")) |> 
  select(series, episode, baker, result)

winner_df |>
  pivot_wider(
    names_from = series,
    values_from = baker
  ) |> 
  arrange(episode) |> 
  knitr::kable()
```

| episode | result     | 5       | 6      | 7       | 8      | 9       | 10    |
|--------:|:-----------|:--------|:-------|:--------|:-------|:--------|:------|
|       1 | STAR BAKER | Nancy   | Marie  | Jane    | Steven | Manon   | NA    |
|       3 | STAR BAKER | Luis    | Ian    | Tom     | Julia  | Rahul   | NA    |
|       5 | STAR BAKER | NA      | Nadiya | Candice | Sophie | NA      | NA    |
|       6 | STAR BAKER | NA      | NA     | NA      | NA     | NA      | Steph |
|       7 | STAR BAKER | NA      | Tamal  | Andrew  | Steven | Kim-Joy | Henry |
|       8 | STAR BAKER | Richard | NA     | NA      | NA     | NA      | Steph |
|       9 | STAR BAKER | NA      | Nadiya | Andrew  | Sophie | Ruby    | Alice |
|      10 | WINNER     | NA      | Nadiya | Candice | Sophie | Rahul   | NA    |

Most of the winners were unsurprising, as each of them had previously
been a star baker. David, on the other hand, was the winner of series 10
and had not previously been crowned star baker at any point.

Import, clean, tidy, and organize the viewership data in viewers.csv.
Show the first 10 rows of this dataset. What was the average viewership
in Season 1? In Season 5?

``` r
viewers_df = 
  read_csv("data/viewers.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = series_1:series_10,
    names_to = "series",
    values_to = "viewership",
    names_prefix = "series_"
  ) |> 
  mutate(
    series = as.numeric(series)
  ) |> 
  arrange(series) |> 
  relocate(series)
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
knitr::kable(head(viewers_df, 10))
```

| series | episode | viewership |
|-------:|--------:|-----------:|
|      1 |       1 |       2.24 |
|      1 |       2 |       3.00 |
|      1 |       3 |       3.00 |
|      1 |       4 |       2.60 |
|      1 |       5 |       3.03 |
|      1 |       6 |       2.75 |
|      1 |       7 |         NA |
|      1 |       8 |         NA |
|      1 |       9 |         NA |
|      1 |      10 |         NA |

``` r
viewers_df |> 
  filter(series == 1) |> 
  summarise(mean(viewership, na.rm = TRUE))
```

    ## # A tibble: 1 × 1
    ##   `mean(viewership, na.rm = TRUE)`
    ##                              <dbl>
    ## 1                             2.77

``` r
viewers_df |> 
  filter(series == 5) |> 
  summarise(mean(viewership, na.rm = TRUE))
```

    ## # A tibble: 1 × 1
    ##   `mean(viewership, na.rm = TRUE)`
    ##                              <dbl>
    ## 1                             10.0

The average viewership in Season 1 was 2.77 and in Season 5 it was 10.0.
