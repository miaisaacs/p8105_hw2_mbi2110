---
title: "Homework 2"
author: "Mia Isaacs"
date: "2024-09-29"
output: github_document
---

# load necessary packages

```{r}
library(tidyverse)
library(readxl)
```

# problem 1 - NYC transit data

Read and clean the data; retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character (YES vs NO) to a logical variable.

```{r}
nyc_df = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) |> 
  janitor::clean_names() |> 
  select(line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) |> 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))

view(nyc_df)
```


Write a short paragraph about this dataset â€“ explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset. Are these data tidy?

```{r}
nrow(nyc_df)
ncol(nyc_df)
colnames(nyc_df)
```
 
This dataset contains 19 columns and 1868 rows, consisting of the variables line, name, latitude, longitude, routes 1-11, entrance type, entry, vending, and ada compliance. To clean my data, I used the clean_names step to make the variable naming convention consistent and I selected for the variables of interest. I used a mutate step to change the entry variable from yes/no to a logical variable and specified that routes 8-11 should also be character. These data are not tidy because route and route number should be variables, which means we would have to convert them from wide to long format.


How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway; 125st Lenox); the distinct function may be useful here.

```{r}
nyc_df |> 
  select(station_name, line) |> 
  distinct()
```

There are 465 distinct stations.


How many stations are ADA compliant?

```{r}
nyc_df |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

Only 84 stations are ADA compliant.


What proportion of station entrances / exits without vending allow entrance?

```{r}
nyc_df |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
```

The proportion of station entrances/exits without vending allow entrance is 0.3770492.


Reformat data so that route number and route name are distinct variables. How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

```{r}
nyc_df |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()

nyc_df |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

60 distinct stations serve the A train. Of that stations that serve the A train, only 17 are ADA compliant.


# problem 2 - mr. trash wheel data

Read and clean the Mr. Trash Wheel sheet:specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel, use reasonable variable names, omit rows that do not include dumpster-specific data, round the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)

```{r}
mr_trash_df =
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             na = c("NA", ".", ""),
             sheet = "Mr. Trash Wheel", range = "A2:N653") |> 
  janitor::clean_names() |> 
  rename(
    weight = weight_tons, 
    volume = volume_cubic_yards) |> 
  select(-homes_powered) |> 
  mutate(
    sports_balls = as.integer(
    round(sports_balls)),
    trash_type = "Mr. Trash Wheel",
    year = as.integer(year)
    ) 
```


Use a similar process to import, clean, and organize the data for Professor Trash Wheel and Gwynnda, and combine this with the Mr. Trash Wheel dataset to produce a single tidy dataset. To keep track of which Trash Wheel is which, you may need to add an additional variable to both datasets before combining.

```{r}
prof_trash_df =
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             na = c("NA", ".", ""),
             sheet = "Professor Trash Wheel", range = "A2:M120") |> 
  janitor::clean_names() |> 
  rename(
    weight = weight_tons, 
    volume = volume_cubic_yards) |> 
  select(-homes_powered) |> 
  mutate(trash_type = "Prof. Trash Wheel",
         year = as.integer(year))
```

```{r}
gwynnda_df =
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 
             na = c("NA", ".", ""),
             sheet = "Gwynnda Trash Wheel", range = "A2:L265") |> 
  janitor::clean_names() |> 
    rename(
    weight = weight_tons, 
    volume = volume_cubic_yards) |> 
  select(-homes_powered) |> 
  mutate(trash_type = "Gwynnda Trash Wheel",
         year = as.integer(year))
```

```{r}
all_trash_df =
  bind_rows(mr_trash_df, prof_trash_df, gwynnda_df)
```

Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of cigarette butts collected by Gwynnda in June of 2022?

The all_trash_df consists of data from three separate Trash Wheels: Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel. There are `r nrow(all_trash_df)` total observations and the variables include `r names(all_trash_df)`.

```{r}
all_trash_df |> 
  filter(trash_type == "Prof. Trash Wheel") |> 
  summarise(sum(weight))
```

The total weight of trash collected by Professor Trash Wheel is 247 tons.

```{r}
all_trash_df |> 
  filter(trash_type == "Gwynnda Trash Wheel", 
         month == "June",
         year == 2022) |> 
  summarise(sum(cigarette_butts))
```

In June of 2022, Gwynnda collected a total of 18,120 cigarette butts.


# problem 3 - great british bake off

In the first part of this problem, your goal is to create a single, well-organized dataset with all the information contained in these data files. To that end: import, clean, tidy, and otherwise wrangle each of these datasets; check for completeness and correctness across datasets (e.g. by viewing individual datasets and using anti_join); merge to create a single, final dataset; and organize this so that variables and observations are in meaningful orders. Export the result as a CSV in the directory containing the original datasets.

```{r}
bakers_df =
  read_csv("data/bakers.csv") |> 
  janitor::clean_names() |> 
  mutate(baker = word(baker_name, 1))
```

```{r}
bakes_df =
  read_csv("data/bakes.csv", na = c("NA", "N/A", "UNKNOWN", "")) |> 
  janitor::clean_names()
```

```{r}
results_df =
  read_csv("data/results.csv", skip = 2,
           na = c("NA", "N/A", "UNKNOWN", ""))
```

```{r}

```








